{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1826dd7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T04:56:18.665393Z",
     "start_time": "2022-01-12T04:56:11.082405Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score,recall_score,f1_score,confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8b67d93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T04:56:18.680078Z",
     "start_time": "2022-01-12T04:56:18.670888Z"
    }
   },
   "outputs": [],
   "source": [
    "df_full_r = os.path.join(os.getcwd(), \"member_type_prediction_full_record.csv\")\n",
    "df_5_r = os.path.join(os.getcwd(), \"member_type_prediction_5record.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14f918d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T04:56:18.816422Z",
     "start_time": "2022-01-12T04:56:18.684207Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(df_5_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b38363a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T04:56:18.877870Z",
     "start_time": "2022-01-12T04:56:18.820047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>member_id</th>\n",
       "      <th>member_age</th>\n",
       "      <th>member_gender</th>\n",
       "      <th>member_total_distance</th>\n",
       "      <th>member_period</th>\n",
       "      <th>wd_ratio</th>\n",
       "      <th>usage_per_week</th>\n",
       "      <th>interval_mean</th>\n",
       "      <th>interval_med</th>\n",
       "      <th>interval_std</th>\n",
       "      <th>...</th>\n",
       "      <th>car_type_gini</th>\n",
       "      <th>zone_gini</th>\n",
       "      <th>trip_gini</th>\n",
       "      <th>attraction_mean</th>\n",
       "      <th>attraction_std</th>\n",
       "      <th>restaurant_mean</th>\n",
       "      <th>restaurant_std</th>\n",
       "      <th>shopping_mean</th>\n",
       "      <th>shopping_std</th>\n",
       "      <th>member_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>male</td>\n",
       "      <td>8774.0</td>\n",
       "      <td>1425</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.115894</td>\n",
       "      <td>8.223958</td>\n",
       "      <td>8.854167</td>\n",
       "      <td>5.366304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.428380</td>\n",
       "      <td>0.398057</td>\n",
       "      <td>19.438700</td>\n",
       "      <td>3.798821</td>\n",
       "      <td>1.208576</td>\n",
       "      <td>0.590071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>male</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>755</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.117057</td>\n",
       "      <td>33.994792</td>\n",
       "      <td>30.024306</td>\n",
       "      <td>14.787664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.736111</td>\n",
       "      <td>0.237014</td>\n",
       "      <td>0.299347</td>\n",
       "      <td>11.824094</td>\n",
       "      <td>0.914811</td>\n",
       "      <td>1.121910</td>\n",
       "      <td>0.201928</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>male</td>\n",
       "      <td>7105.0</td>\n",
       "      <td>586</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.115512</td>\n",
       "      <td>27.708333</td>\n",
       "      <td>26.326389</td>\n",
       "      <td>10.186635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.760331</td>\n",
       "      <td>0.617962</td>\n",
       "      <td>0.737226</td>\n",
       "      <td>15.569857</td>\n",
       "      <td>3.524970</td>\n",
       "      <td>1.535372</td>\n",
       "      <td>0.537232</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "      <td>male</td>\n",
       "      <td>1881.0</td>\n",
       "      <td>2235</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.117450</td>\n",
       "      <td>22.281250</td>\n",
       "      <td>24.645833</td>\n",
       "      <td>8.905775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.641975</td>\n",
       "      <td>0.121984</td>\n",
       "      <td>0.055053</td>\n",
       "      <td>12.989093</td>\n",
       "      <td>1.141449</td>\n",
       "      <td>1.011056</td>\n",
       "      <td>0.136639</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>male</td>\n",
       "      <td>5734.0</td>\n",
       "      <td>435</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>38.510417</td>\n",
       "      <td>28.440972</td>\n",
       "      <td>26.973121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.871111</td>\n",
       "      <td>0.701803</td>\n",
       "      <td>0.623375</td>\n",
       "      <td>22.212247</td>\n",
       "      <td>4.153058</td>\n",
       "      <td>1.840245</td>\n",
       "      <td>0.906086</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   member_id  member_age member_gender  member_total_distance  member_period  \\\n",
       "0          1          35          male                 8774.0           1425   \n",
       "1         10          26          male                 9550.0            755   \n",
       "2         13          40          male                 7105.0            586   \n",
       "3         15          38          male                 1881.0           2235   \n",
       "4         22          21          male                 5734.0            435   \n",
       "\n",
       "   wd_ratio  usage_per_week  interval_mean  interval_med  interval_std  ...  \\\n",
       "0       0.8        0.115894       8.223958      8.854167      5.366304  ...   \n",
       "1       0.6        0.117057      33.994792     30.024306     14.787664  ...   \n",
       "2       1.0        0.115512      27.708333     26.326389     10.186635  ...   \n",
       "3       0.6        0.117450      22.281250     24.645833      8.905775  ...   \n",
       "4       0.4        0.116667      38.510417     28.440972     26.973121  ...   \n",
       "\n",
       "   car_type_gini  zone_gini  trip_gini  attraction_mean  attraction_std  \\\n",
       "0           0.32       0.56   0.906667         0.428380        0.398057   \n",
       "1           0.56       0.56   0.736111         0.237014        0.299347   \n",
       "2           0.64       0.32   0.760331         0.617962        0.737226   \n",
       "3           0.32       0.56   0.641975         0.121984        0.055053   \n",
       "4           0.00       0.64   0.871111         0.701803        0.623375   \n",
       "\n",
       "   restaurant_mean restaurant_std  shopping_mean  shopping_std  member_type  \n",
       "0        19.438700       3.798821       1.208576      0.590071            0  \n",
       "1        11.824094       0.914811       1.121910      0.201928            3  \n",
       "2        15.569857       3.524970       1.535372      0.537232            1  \n",
       "3        12.989093       1.141449       1.011056      0.136639            1  \n",
       "4        22.212247       4.153058       1.840245      0.906086            2  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d114b3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T04:56:56.663137Z",
     "start_time": "2022-01-12T04:56:56.646466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['member_id', 'member_age', 'member_gender', 'member_total_distance',\n",
       "       'member_period', 'wd_ratio', 'usage_per_week', 'interval_mean',\n",
       "       'interval_med', 'interval_std', 'usage_time_mean', 'usage_time_std',\n",
       "       'usage_time_med', 'vroom_per_usage', 'num_trips_mean', 'num_trips_std',\n",
       "       'car_type_mode', 'car_type_gini', 'zone_gini', 'trip_gini',\n",
       "       'attraction_mean', 'attraction_std', 'restaurant_mean',\n",
       "       'restaurant_std', 'shopping_mean', 'shopping_std', 'member_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ad0ae40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T04:56:57.467703Z",
     "start_time": "2022-01-12T04:56:57.441625Z"
    }
   },
   "outputs": [],
   "source": [
    "df['member_gender'] = df['member_gender'].replace(['male', 'female'], [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4ad5912",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T04:56:59.262841Z",
     "start_time": "2022-01-12T04:56:59.240119Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df['car_type_mode'])\n",
    "df['car_type_mode'] = le.transform(df['car_type_mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07188087",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T04:57:00.729887Z",
     "start_time": "2022-01-12T04:57:00.715843Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:,1:-1] #feature\n",
    "y = df.iloc[:,-1] #target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a68dd4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T04:57:08.843098Z",
     "start_time": "2022-01-12T04:57:08.799292Z"
    }
   },
   "outputs": [],
   "source": [
    "col = ['member_age', 'member_total_distance', 'member_period', 'wd_ratio', 'usage_per_week', 'interval_mean',\n",
    "       'interval_med', 'interval_std', 'usage_time_mean', 'usage_time_std', 'usage_time_med', 'vroom_per_usage',\n",
    "       'num_trips_mean', 'num_trips_std', 'car_type_gini', 'zone_gini', 'trip_gini', 'attraction_mean', \n",
    "       'attraction_std', 'restaurant_mean', 'restaurant_std', 'shopping_mean', 'shopping_std']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#  standard scaler적용\n",
    "scaler_option = 'ss'\n",
    "if scaler_option == 'ss':\n",
    "    scaler = StandardScaler()\n",
    "elif scaler_option == 'mms':\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "scaled_X = X.copy()\n",
    "scaled_X[col] = scaler.fit_transform(scaled_X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8d1454d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T04:57:13.224655Z",
     "start_time": "2022-01-12T04:57:13.175173Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    3155\n",
       "3    2875\n",
       "1    2860\n",
       "0    1991\n",
       "Name: member_type, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, stratify=y.to_numpy())\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "056a9e30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T04:57:14.914183Z",
     "start_time": "2022-01-12T04:57:14.889866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    789\n",
       "3    719\n",
       "1    715\n",
       "0    498\n",
       "Name: member_type, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f656217e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T04:57:15.954811Z",
     "start_time": "2022-01-12T04:57:15.392490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3155\n",
       "3    3155\n",
       "2    3155\n",
       "0    3155\n",
       "Name: member_type, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imbalanced data 오버 샘플링 처리\n",
    "x_resampled, y_resampled = SMOTE(random_state=0).fit_resample(x_train, y_train)\n",
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6f6a87b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T04:57:17.499753Z",
     "start_time": "2022-01-12T04:57:17.478183Z"
    }
   },
   "outputs": [],
   "source": [
    "model_X = x_resampled.copy()\n",
    "model_y = y_resampled.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc6103a",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ada6a2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T13:26:11.229114Z",
     "start_time": "2022-01-11T13:26:07.210113Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "12 fits failed out of a total of 24.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.83201268        nan 0.87622821        nan 0.88494453\n",
      "        nan 0.88510301        nan 0.88494453        nan 0.88502377]\n",
      "  warnings.warn(\n",
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=LogisticRegression(random_state=10),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid = {'C' : [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "             'penalty' : [\"l1\",\"l2\"]\n",
    "             }\n",
    "#모델 파라미터 조정(규제 파라미터 및 반복 학습 횟수)\n",
    "lr = LogisticRegression(random_state=10)\n",
    "grid_search = GridSearchCV(lr, param_grid=param_grid, cv=2)\n",
    "grid_search.fit(model_X, model_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9de0b4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T13:26:29.321426Z",
     "start_time": "2022-01-11T13:26:29.313101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter: {'C': 1, 'penalty': 'l2'}\n",
      "Best Score: 0.8851\n",
      "Test Score: 0.8780\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameter: {}'.format(grid_search.best_params_))\n",
    "print('Best Score: {:.4f}'.format(grid_search.best_score_))\n",
    "print('Test Score: {:.4f}'.format(grid_search.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c8e8404",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T13:29:30.935864Z",
     "start_time": "2022-01-11T13:29:30.901783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87       498\n",
      "           1       0.91      0.90      0.91       715\n",
      "           2       0.88      0.87      0.88       789\n",
      "           3       0.86      0.85      0.86       719\n",
      "\n",
      "    accuracy                           0.88      2721\n",
      "   macro avg       0.88      0.88      0.88      2721\n",
      "weighted avg       0.88      0.88      0.88      2721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pred_y = grid_search.best_estimator_.predict(x_test)\n",
    "\n",
    "cfreport_test = classification_report(y_test, pred_y)\n",
    "print(cfreport_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77db65bc",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8294e174",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T05:01:35.684379Z",
     "start_time": "2022-01-12T05:01:13.190967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [10, 11, 12, 13, 14, 15, 16],\n",
       "                         'min_samples_leaf': [3, 4, 5, 6, 7, 8, 9, 10, 11]})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "param_grid = {'max_depth' : [10,11,12,13, 14, 15, 16],\n",
    "             'min_samples_leaf' : [3,4,5,6,7,8,9,10,11]\n",
    "             }\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(dt_clf, param_grid=param_grid, cv=2)\n",
    "grid_search.fit(model_X, model_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f914582",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T05:00:33.227171Z",
     "start_time": "2022-01-12T05:00:32.471272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.582139, 정밀도 : 0.581805, 재현율 : 0.580340\n",
      "f1-score : 0.577156\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier(max_depth=12, min_samples_leaf=5)\n",
    "dt_clf.fit(model_X, model_y)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score,recall_score,f1_score,confusion_matrix, roc_auc_score\n",
    "final_model = dt_clf\n",
    "final_pred = final_model.predict(x_test)\n",
    "\n",
    "def metric(y_test, pred):\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test,pred, average='macro')\n",
    "    recall = recall_score(y_test,pred, average='macro')\n",
    "    f1 = f1_score(y_test,pred, average='macro')\n",
    "    print('정확도 : {0:.6f}, 정밀도 : {1:.6f}, 재현율 : {2:.6f}'.format(accuracy,precision,recall))\n",
    "    print('f1-score : {0:.6f}'.format(f1))\n",
    "\n",
    "metric(y_test, final_pred)\n",
    "\n",
    "# confusion matrix 확인하기\n",
    "\n",
    "\n",
    "con_mat = confusion_matrix(y_test, final_pred)\n",
    "sns.heatmap(con_mat, square=True, annot=True, fmt='d')\n",
    "plt.xlabel('true_label')\n",
    "plt.ylabel('predicted_label')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "#################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1196e4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T05:01:49.228439Z",
     "start_time": "2022-01-12T05:01:49.203694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter: {'max_depth': 10, 'min_samples_leaf': 11}\n",
      "Best Score: 0.6067\n",
      "Test Score: 0.5994\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameter: {}'.format(grid_search.best_params_))\n",
    "print('Best Score: {:.4f}'.format(grid_search.best_score_))\n",
    "print('Test Score: {:.4f}'.format(grid_search.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c69e85d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T13:35:33.068345Z",
     "start_time": "2022-01-11T13:35:33.043017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       498\n",
      "           1       0.90      0.90      0.90       715\n",
      "           2       0.91      0.87      0.89       789\n",
      "           3       0.87      0.88      0.88       719\n",
      "\n",
      "    accuracy                           0.89      2721\n",
      "   macro avg       0.88      0.89      0.88      2721\n",
      "weighted avg       0.89      0.89      0.89      2721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_y = grid_search.best_estimator_.predict(x_test)\n",
    "\n",
    "cfreport_test = classification_report(y_test, pred_y)\n",
    "print(cfreport_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb8142",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aaaa5943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:07:38.105398Z",
     "start_time": "2022-01-11T13:42:11.034280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(random_state=10),\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'max_depth': [10, 15, 25, 30],\n",
       "                         'min_samples_split': [5, 10, 15, 20],\n",
       "                         'n_estimators': range(100, 1000, 100)})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "              'n_estimators': range(100, 1000, 100),\n",
    "              'max_depth': [10, 15, 25, 30],\n",
    "              'min_samples_split' : [5, 10, 15,20],\n",
    "              'bootstrap':[True, False]\n",
    "              }\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=10)\n",
    "grid_search = GridSearchCV(rf_clf, param_grid=param_grid, cv=2)\n",
    "grid_search.fit(model_X, model_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7bcee6bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:07:38.593543Z",
     "start_time": "2022-01-11T16:07:38.110886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter: {'bootstrap': False, 'max_depth': 25, 'min_samples_split': 5, 'n_estimators': 800}\n",
      "Best Score: 0.9151\n",
      "Test Score: 0.9247\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameter: {}'.format(grid_search.best_params_))\n",
    "print('Best Score: {:.4f}'.format(grid_search.best_score_))\n",
    "print('Test Score: {:.4f}'.format(grid_search.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "22a1dae1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:07:39.062864Z",
     "start_time": "2022-01-11T16:07:38.595558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.90       498\n",
      "           1       0.93      0.94      0.94       715\n",
      "           2       0.93      0.93      0.93       789\n",
      "           3       0.91      0.93      0.92       719\n",
      "\n",
      "    accuracy                           0.92      2721\n",
      "   macro avg       0.92      0.92      0.92      2721\n",
      "weighted avg       0.92      0.92      0.92      2721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_y = grid_search.best_estimator_.predict(x_test)\n",
    "\n",
    "cfreport_test = classification_report(y_test, pred_y)\n",
    "print(cfreport_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543dd5d4",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e200d318",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:11:30.461849Z",
     "start_time": "2022-01-11T16:07:39.065381Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:07:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:07:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:07:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:07:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:08:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:08:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:08:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:08:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:08:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:08:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:08:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:08:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:08:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:09:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:09:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:09:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:09:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:09:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:09:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:09:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:09:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:09:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:10:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:10:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:10:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:10:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:10:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:10:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:10:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:10:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:10:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:11:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:11:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     enable_categorical=False, gamma=None,\n",
       "                                     gpu_id=None, importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             param_grid={'colsample_bytree': [0.8, 0.9], 'max_depth': [8, 10],\n",
       "                         'min_child_weight': [5, 8], 'n_estimators': [400, 450],\n",
       "                         'nthread': [8], 'objective': ['multi:softmax']})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "param_grid = {\n",
    "              'n_estimators': [400,450],\n",
    "              'max_depth':[8,10],\n",
    "              'min_child_weight':[5,8],\n",
    "              'nthread':[8],\n",
    "              'colsample_bytree':[0.8,0.9],\n",
    "              'objective':['multi:softmax']\n",
    "              }\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "grid_search = GridSearchCV(xgb, param_grid=param_grid, cv=2)\n",
    "grid_search.fit(model_X, model_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8f5b386",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:11:30.507617Z",
     "start_time": "2022-01-11T16:11:30.463328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameter: {'colsample_bytree': 0.9, 'max_depth': 8, 'min_child_weight': 5, 'n_estimators': 450, 'nthread': 8, 'objective': 'multi:softmax'}\n",
      "Best Score: 0.9431\n",
      "Test Score: 0.9460\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameter: {}'.format(grid_search.best_params_))\n",
    "print('Best Score: {:.4f}'.format(grid_search.best_score_))\n",
    "print('Test Score: {:.4f}'.format(grid_search.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "736e849c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:11:30.568174Z",
     "start_time": "2022-01-11T16:11:30.509380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       498\n",
      "           1       0.95      0.96      0.95       715\n",
      "           2       0.95      0.96      0.96       789\n",
      "           3       0.93      0.94      0.94       719\n",
      "\n",
      "    accuracy                           0.95      2721\n",
      "   macro avg       0.95      0.94      0.94      2721\n",
      "weighted avg       0.95      0.95      0.95      2721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_y = grid_search.best_estimator_.predict(x_test)\n",
    "\n",
    "cfreport_test = classification_report(y_test, pred_y)\n",
    "print(cfreport_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf1a303",
   "metadata": {},
   "source": [
    "### Ensemble Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f1c1afa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T05:04:23.652811Z",
     "start_time": "2022-01-12T05:04:22.886493Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cfb2c8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T05:08:40.214138Z",
     "start_time": "2022-01-12T05:04:23.657785Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:05:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:07:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1, random_state=10)),\n",
       "                             ('dt',\n",
       "                              DecisionTreeClassifier(max_depth=12,\n",
       "                                                     min_samples_leaf=5)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(bootstrap=False,\n",
       "                                                     max_depth=25,\n",
       "                                                     min_samples_split=5,\n",
       "                                                     n_estimators=800,\n",
       "                                                     random_state=10)),\n",
       "                             ('xgb',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            col...\n",
       "                                            max_delta_step=None, max_depth=8,\n",
       "                                            min_child_weight=5, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=450, n_jobs=None,\n",
       "                                            nthread=8, num_parallel_tree=None,\n",
       "                                            objective='multi:softmax',\n",
       "                                            predictor=None, random_state=None,\n",
       "                                            reg_alpha=None, reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            validate_parameters=None,\n",
       "                                            verbosity=None))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "lr = LogisticRegression(random_state=10, C=1, penalty='l2')\n",
    "dt_clf = DecisionTreeClassifier(max_depth=12, min_samples_leaf=5)\n",
    "rf_clf = RandomForestClassifier(random_state=10, bootstrap=False, max_depth=25, min_samples_split=5, n_estimators=800)\n",
    "xgb = XGBClassifier(colsample_bytree=0.9, max_depth=8, min_child_weight=5, n_estimators=450, nthread=8, objective='multi:softmax')\n",
    "voting_hard = VotingClassifier(\n",
    "                estimators = [('lr', lr), ('dt', dt_clf), ('rf', rf_clf), ('xgb', xgb)], voting='hard')\n",
    "voting_soft = VotingClassifier(\n",
    "                estimators = [('lr', lr), ('dt', dt_clf), ('rf', rf_clf), ('xgb', xgb)], voting='soft')\n",
    "voting_hard.fit(model_X, model_y)\n",
    "voting_soft.fit(model_X, model_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "abfa53ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T01:39:13.044863Z",
     "start_time": "2022-01-12T01:34:16.114967Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.6391032708563028\n",
      "DecisionTreeClassifier 0.5942668136714443\n",
      "RandomForestClassifier 0.6486585814038957\n",
      "[10:35:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier 0.6361631753031973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:36:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "VotingClassifier 0.6449834619625138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "E:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:38:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "VotingClassifier 0.6523337008452774\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (lr, dt_clf, rf_clf, xgb, voting_hard, voting_soft):\n",
    "    clf.fit(model_X, model_y)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71c5f2ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T01:39:13.851372Z",
     "start_time": "2022-01-12T01:39:13.048709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.52      0.51       498\n",
      "           1       0.64      0.66      0.65       715\n",
      "           2       0.72      0.71      0.71       789\n",
      "           3       0.68      0.65      0.66       719\n",
      "\n",
      "    accuracy                           0.64      2721\n",
      "   macro avg       0.63      0.63      0.63      2721\n",
      "weighted avg       0.65      0.64      0.65      2721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "pred_y = voting_hard.predict(x_test)\n",
    "\n",
    "cfreport_test = classification_report(y_test, pred_y)\n",
    "print(cfreport_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af2a1ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T01:39:14.551012Z",
     "start_time": "2022-01-12T01:39:13.854382Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.48      0.50       498\n",
      "           1       0.64      0.67      0.66       715\n",
      "           2       0.72      0.72      0.72       789\n",
      "           3       0.67      0.68      0.68       719\n",
      "\n",
      "    accuracy                           0.65      2721\n",
      "   macro avg       0.64      0.64      0.64      2721\n",
      "weighted avg       0.65      0.65      0.65      2721\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "pred_y = voting_soft.predict(x_test)\n",
    "\n",
    "cfreport_test = classification_report(y_test, pred_y)\n",
    "print(cfreport_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd8afcee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T05:08:41.543390Z",
     "start_time": "2022-01-12T05:08:40.216344Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.664462, 정밀도 : 0.653630, 재현율 : 0.653844\n",
      "f1-score : 0.653494\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score,recall_score,f1_score,confusion_matrix, roc_auc_score\n",
    "final_model = voting_soft\n",
    "final_pred = final_model.predict(x_test)\n",
    "\n",
    "def metric(y_test, pred):\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test,pred, average='macro')\n",
    "    recall = recall_score(y_test,pred, average='macro')\n",
    "    f1 = f1_score(y_test,pred, average='macro')\n",
    "    print('정확도 : {0:.6f}, 정밀도 : {1:.6f}, 재현율 : {2:.6f}'.format(accuracy,precision,recall))\n",
    "    print('f1-score : {0:.6f}'.format(f1))\n",
    "\n",
    "metric(y_test, final_pred)\n",
    "\n",
    "# confusion matrix 확인하기\n",
    "\n",
    "\n",
    "con_mat = confusion_matrix(y_test, final_pred)\n",
    "sns.heatmap(con_mat, square=True, annot=True, fmt='d')\n",
    "plt.xlabel('true_label')\n",
    "plt.ylabel('predicted_label')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4223540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3071d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389bdf6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dba7ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec5a21f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a89db5d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:12:12.176609Z",
     "start_time": "2022-01-12T02:12:12.121746Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'key of type tuple not found and not a MultiIndex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10904/1663781272.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mfpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mroc_auc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    964\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    979\u001b[0m             )\n\u001b[0;32m    980\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\hong9\\Anaconda3\\envs\\cv2_study\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_values_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"key of type tuple not found and not a MultiIndex\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m         \u001b[1;31m# If key is contained, would have returned by now\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'key of type tuple not found and not a MultiIndex'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_score = model.fit().decision_function(x_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b83dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "n_classes = y_train.to_numpy()\n",
    "\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(y_train.nunique())]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(\n",
    "    fpr[\"micro\"],\n",
    "    tpr[\"micro\"],\n",
    "    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n",
    "    color=\"deeppink\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    fpr[\"macro\"],\n",
    "    tpr[\"macro\"],\n",
    "    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n",
    "    color=\"navy\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(\n",
    "        fpr[i],\n",
    "        tpr[i],\n",
    "        color=color,\n",
    "        lw=lw,\n",
    "        label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),\n",
    "    )\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Some extension of Receiver operating characteristic to multiclass\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ead69d0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T01:56:58.722790Z",
     "start_time": "2022-01-12T01:56:58.708315Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame({'value' : y_test.to_numpy(), 'pred' : pred_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "842f1901",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:39:49.713133Z",
     "start_time": "2022-01-12T02:39:49.692823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    104\n",
       "2     74\n",
       "3     38\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.loc[(df_pred['pred']==0) & (df_pred['value']!= df_pred['pred']), 'value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7fd272e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:39:50.199178Z",
     "start_time": "2022-01-12T02:39:50.188194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    239\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.loc[(df_pred['pred']==0) & (df_pred['value']== df_pred['pred']), 'value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76136106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc72b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b18e7d08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T02:37:28.502157Z",
     "start_time": "2022-01-12T02:37:28.480352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    239\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.loc[(df_pred['pred']==0) & (df_pred['value']== df_pred['pred']), 'value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772852a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.loc[(df_pred['value']==0) & (df_pred['value']== df_pred['pred']), 'pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e797ebab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T01:58:53.293514Z",
     "start_time": "2022-01-12T01:58:53.270326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    104\n",
       "3     92\n",
       "2     39\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.loc[(df_pred['value']==1) & (df_pred['value']!= df_pred['pred']), 'pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "178f6186",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T01:58:59.816396Z",
     "start_time": "2022-01-12T01:58:59.799330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    90\n",
       "0    74\n",
       "1    59\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.loc[(df_pred['value']==2) & (df_pred['value']!= df_pred['pred']), 'pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0dc27f46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T01:59:10.977581Z",
     "start_time": "2022-01-12T01:59:10.967329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    96\n",
       "1    95\n",
       "0    38\n",
       "Name: pred, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.loc[(df_pred['value']==3) & (df_pred['value']!= df_pred['pred']), 'pred'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb2baa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:11:35.552432Z",
     "start_time": "2022-01-11T16:11:35.552432Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=10, C=1, penalty='l2')\n",
    "dt_clf = DecisionTreeClassifier(max_depth=12, min_samples_leaf=5)\n",
    "rf_clf = RandomForestClassifier(random_state=10)\n",
    "\n",
    "voting_hard = VotingClassifier(\n",
    "                estimators = [('lr', lr), ('dt', dt_clf), ('rf', rf_clf)], voting='soft')\n",
    "voting_hard.fit(model_X, model_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45db5a90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:11:35.554757Z",
     "start_time": "2022-01-11T16:11:35.554757Z"
    }
   },
   "outputs": [],
   "source": [
    "for clf in (lr, dt_clf, rf_clf, voring_hard):\n",
    "    clf.fit(model_X, model_y)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cb3476",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-11T16:11:35.557259Z",
     "start_time": "2022-01-11T16:11:35.557259Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_y = voting_hard.predict(x_test)\n",
    "\n",
    "cfreport_test = classification_report(y_test, pred_y)\n",
    "print(cfreport_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c67c9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aa65bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e024dff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef0d1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model_X.columns\n",
    "num_features = len(features)\n",
    "def plot_feature_importances(model):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    n_features = num_features\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), features)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)\n",
    "\n",
    "plot_feature_importances(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150e423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3c2a24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ff737b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3b5843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a25d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bd338a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55150f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# k_fold validation 적용 (연산이 오래 걸릴수도 있음)\n",
    "# -> 연산이 너무 많이 걸리지 않는 선에서 최대 효율을 뽑을 필요가 있어보임\n",
    "k_fold = KFold(random_state=50, n_splits=5, shuffle=True)\n",
    "\n",
    "# 모델 설정\n",
    "#model = RandomForestClassifier()\n",
    "model = XGBClassifier()\n",
    "#model = LGBMClassifier()\n",
    "\n",
    "# 그리드 서치 파라미터 설정\n",
    "\n",
    "# RandomForest 파라미터\n",
    "'''\n",
    "param_grid = {\n",
    "              'n_estimators': [200, 250],\n",
    "              'max_depth': [25,30],\n",
    "              'min_samples_split' : [15,20],\n",
    "              'bootstrap':['False','True'],\n",
    "              'min_samples_leaf': [10,15],\n",
    "              }\n",
    "'''   \n",
    "\n",
    "#XGBoost 파라미터\n",
    "param_grid = {\n",
    "              'n_estimators': [400,450],\n",
    "              'max_depth':[8,10],\n",
    "              'min_child_weight':[5,8], #min sample leaf\n",
    "              'nthread':[8], #스레드 갯수 고정\n",
    "              'colsample_bytree':[0.8,0.9], #max feature\n",
    "              'objective':['multi:softmax']\n",
    "              }\n",
    "\n",
    "\n",
    "'''\n",
    "#lightGBM 파라미터\n",
    "param_grid = {\n",
    "              'n_estimators': [200],\n",
    "              'min_child_samples':[1,2], #과적합을 방지하는 파라미터\n",
    "              'max_depth':[7,8,10],\n",
    "              'num_leaves':[70],\n",
    "              'sub_sample':[0.2,0.4] #과적합 방지하기 위해 데이터 샘플링 하는 비율\n",
    "              }\n",
    "'''\n",
    "\n",
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = param_grid,\n",
    "                           cv = k_fold)\n",
    "\n",
    "grid_search.fit(x_resampled, y_resampled)\n",
    "best_param = grid_search.best_params_\n",
    "\n",
    "# 최적 파라미터와 결과\n",
    "print(best_param)\n",
    "print('best score : {}'.format(grid_search.best_score_))\n",
    "\n",
    "# 최종 모델 평가\n",
    "from sklearn.metrics import accuracy_score, precision_score,recall_score,f1_score,confusion_matrix, roc_auc_score\n",
    "final_model = grid_search.best_estimator_\n",
    "final_pred = final_model.predict(x_test)\n",
    "\n",
    "def metric(y_test, pred):\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test,pred, average='macro')\n",
    "    recall = recall_score(y_test,pred, average='macro')\n",
    "    f1 = f1_score(y_test,pred, average='macro')\n",
    "    print('정확도 : {0:.6f}, 정밀도 : {1:.6f}, 재현율 : {2:.6f}'.format(accuracy,precision,recall))\n",
    "    print('f1-score : {0:.6f}'.format(f1))\n",
    "\n",
    "metric(y_test, final_pred)\n",
    "\n",
    "# confusion matrix 확인하기\n",
    "\n",
    "\n",
    "con_mat = confusion_matrix(y_test, final_pred)\n",
    "sns.heatmap(con_mat, square=True, annot=True, fmt='d')\n",
    "plt.xlabel('true_label')\n",
    "plt.ylabel('predicted_label')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# 특성 중요도 추출하기\n",
    "diction= {}\n",
    "for name, score in zip(df.columns, final_model.feature_importances_):\n",
    "    #print(name, score)\n",
    "    diction[name]=score\n",
    "    \n",
    "feature_importance = pd.DataFrame(list(diction.items()), columns=['features', 'score'])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='features', y='score', data=feature_importance)\n",
    "plt.title('Feature Importances', fontsize=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2af482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed38efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0818dff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbadfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
